{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# C7082 Assignment: Mushroom classification\n",
    "Student number: 23381200\n",
    "Date: xx-xx-xx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Classifier training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# URL of the raw CSV file in the GitHub repository\n",
    "url = \"https://raw.githubusercontent.com/LientjieColahan/C7082_23381200/refs/heads/main/secondary_data.csv?token=GHSAT0AAAAAAC4TKDTRCHO2EQLCTS2FKJAOZ3ZQWYQ\"\n",
    "\n",
    "# Load the database\n",
    "data = pd.read_csv(url, delimiter=';')\n",
    "\n",
    "# Separate features and target\n",
    "X = data.drop('class', axis=1)  # Features\n",
    "y = data['class']  # Target variable\n",
    "\n",
    "# Convert categorical variables to categorical data type\n",
    "categorical_columns = X.select_dtypes(include=['object']).columns\n",
    "X[categorical_columns] = X[categorical_columns].astype('category')\n",
    "\n",
    "# Convert target variable to categorical\n",
    "y = y.astype('category')\n",
    "\n",
    "# Convert continuous variables to float\n",
    "continuous_columns = ['cap-diameter', 'stem-height', 'stem-width']\n",
    "X[continuous_columns] = X[continuous_columns].astype(float)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Display basic information about the dataset\n",
    "print(\"Dataset Info:\")\n",
    "print(\"Features shape:\", X.shape)\n",
    "print(\"Target shape:\", y.shape)\n",
    "print(\"\\nFeature types:\")\n",
    "print(X.dtypes)\n",
    "print(\"\\nTarget type:\", y.dtype)\n",
    "print(\"\\nFirst few rows of the features:\")\n",
    "print(X.info())\n",
    "print(\"\\nFirst few rows of the features:\")\n",
    "print(X.head())\n",
    "print(\"\\nFirst few rows of the target:\")\n",
    "print(y.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory data analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To start check the distribution of the data between edible and poisonous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Check the data spread between edible and poisonous\n",
    "plt.figure(figsize=(10, 6))\n",
    "ax = sns.countplot(x='class', data=data)  # Use 'class' column for x-axis\n",
    "plt.title('Distribution of Edible vs. Poisonous')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "\n",
    "# Calculate percentage for each bar\n",
    "total = len(data['class'])\n",
    "for p in ax.patches:\n",
    "    percentage = '{:.1f}%'.format(100 * p.get_height() / total)\n",
    "    x_coord = p.get_x() + p.get_width() / 2 - 0.1\n",
    "    y_coord = p.get_y() + p.get_height()\n",
    "    ax.annotate(percentage, (x_coord, y_coord), size=12)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is reasonably balanced with a 55.55% to 44.5% spread between poisonous and edible.\n",
    "\n",
    "Next check for missing values in the dataset as these can bias the predictions especially if they match a single output perfectly\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "print(\"\\nMissing values in the dataset:\")\n",
    "missing_values = X.isnull().sum()\n",
    "missing_percentages = (100 * X.isnull().sum() / len(X)).round(2)\n",
    "missing_table = pd.concat([missing_values, missing_percentages], axis=1, keys=['Count', 'Percentage'])\n",
    "missing_table = missing_table[missing_table['Count'] > 0].sort_values('Percentage', ascending=False)\n",
    "print(missing_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset has features with a significant number of missing values.\n",
    "\n",
    "To further investigate the data look at the relationship between the categorical features and how they relate to edible versus poisonous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Explore relationship between categorical features and target variable through bar plot visualisations\n",
    "# Define the number of rows and columns for the grid\n",
    "num_rows = 4\n",
    "num_cols = 5\n",
    "\n",
    "# Create a figure and an array of subplots\n",
    "fig, axes = plt.subplots(num_rows, num_cols, figsize=(20, 16))\n",
    "\n",
    "# Flatten the axes array for easier iteration\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Iterate through categorical columns and plot on subplots\n",
    "categorical_columns = data.select_dtypes(include=['object']).columns\n",
    "for i, column in enumerate(categorical_columns):\n",
    "    sns.countplot(x=column, hue='class', data=data, ax=axes[i])\n",
    "    axes[i].set_title(f'{column} vs. Target Variable', fontsize=10)\n",
    "    axes[i].tick_params(axis='x', rotation=45, labelsize=8)\n",
    "    axes[i].legend(title='Target Variable', fontsize=8)\n",
    "\n",
    "# Adjust layout to prevent overlapping\n",
    "plt.tight_layout()\n",
    "\n",
    "# Hide any unused subplots\n",
    "for i in range(len(categorical_columns), num_rows * num_cols):\n",
    "    fig.delaxes(axes[i])\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Considering the missing values and the relationships between the features and the target it is reasonable to remove:\n",
    "\n",
    "*   Veil-type as it ha >90% missing values and there is only a single veil type in the dataset\n",
    "*   Veil-color as it has >85% missing values and only 1 veil colour encodes information for both the values in the target.\n",
    "* Spore-print-colour as it has >85% missing values and only 3 out of 7 spore print colours encode data for both the values in the target.\n",
    "* Stem-root as it has >80% missing values and only 2 out of 5 stem root types encode data for both values in the target\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop categorical variables which may bias the prediction\n",
    "X.drop(columns=['veil-type', 'veil-color', 'spore-print-color', 'stem-root'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SAY SOMETHING ABOUT THE OTHER MISSING DATA AND HOW RF CAN DEAL WITH MISSING DATA**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training & tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode categorical variables\n",
    "encoder = LabelEncoder()\n",
    "y_encoded = encoder.fit_transform(y)  # Encode target variable (edible=0, poisonous=1)\n",
    "X_encoded = pd.get_dummies(X)  # One-hot encode categorical featuresc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode categorical variables\n",
    "encoder = LabelEncoder()\n",
    "y_encoded = encoder.fit_transform(y)  # Encode target variable (edible=0, poisonous=1)\n",
    "X_encoded = pd.get_dummies(X)  # One-hot encode categorical featuresc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a preliminary RF model to enable feature selection\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Perform feature selection using feature importance\n",
    "feature_importances = pd.DataFrame({'Feature': X_encoded.columns, 'Importance': rf.feature_importances_})\n",
    "feature_importances.sort_values(by='Importance', ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot feature importance\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x='Importance', y='Feature', data=feature_importances.head(10))\n",
    "plt.title('Top 10 Important Features')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter tuning using GridSearchCV (edit parameters to experiment)\n",
    "param_grid = {\n",
    "    'n_estimators': [10 ,100, 150],  # edit this: number of trees in the forest\n",
    "    'max_depth': [1, 10, 20],  # edit this: maximum depth of trees\n",
    "    'min_samples_split': [2, 5, 10],  # edit this: minimum samples required to split an internal node\n",
    "    'min_samples_leaf': [1, 2, 5]   # edit this: minimum samples required to be at a leaf node\n",
    "}\n",
    "grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=8, scoring='accuracy', verbose=2)\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best parameters and model from GridSearchCV\n",
    "best_rf = grid_search.best_estimator_\n",
    "print(\"Best Parameters:\", grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model performance on test set\n",
    "y_pred = best_rf.predict(X_test)\n",
    "y_pred_proba = best_rf.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification report and confusion matrix\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=['Edible', 'Poisonous'], yticklabels=['Edible', 'Poisonous'])\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC Curve and AUC Score\n",
    "fpr, tpr, _ = roc_curve(y_test, y_pred_proba)\n",
    "roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, label=f'ROC Curve (AUC = {roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], 'k--')  # Diagonal line for random guess\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Needs code to save model**"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
