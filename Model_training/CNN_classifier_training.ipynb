{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# C7082 Assignment: Mushroom classification\n",
    "Student number: 23381200\n",
    "Date: xx-xx-xx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Network Training through Transfer Learning\n",
    "Transfer learning using InceptionV3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load necessary libraries\n",
    "import os \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Dropout, Dense\n",
    "\n",
    "!pip install torchvision\n",
    "from torchvision import transforms\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset: insert URL\n",
    "\n",
    "\n",
    "path_to_dataset = \"mushroom_dataset\"\n",
    "train_path = path_to_dataset +\"/train\"\n",
    "test_path = path_to_dataset + \"/test\"\n",
    "valid_path = path_to_dataset + \"/valid\"\n",
    "\n",
    "\n",
    "no_of_classes = len(os.listdir(train_path))\n",
    "print(\"No. of Classes: \" + str(no_of_classes))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# NOT CURRENTLY WORKING - EXCLUDE FOR NOW\n",
    "# view a random image\n",
    "def view_random_image(target_dir, target_class) :\n",
    "    target_folder = target_dir + \"/\" + target_class\n",
    "    # get the random image\n",
    "    random_image = random.sample(os.listdir(target_folder), 1)\n",
    "    # show the image\n",
    "    img = mping.imread(target_folder + \"/\" + random_image[0])\n",
    "    plt.imshow(img)\n",
    "    plt.title(target_class)\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "    print(f\"Image shape: {img.shape}\")\n",
    "    return img\n",
    "\n",
    "img = view_random_image(target_dir=train_path, target_class='poisonous')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Image preprocessing\n",
    "\n",
    "# Data augmentation to generate more data\n",
    "# Define your augmentation parameters\n",
    "datagen = ImageDataGenerator(\n",
    "    preprocessing_function=tf.keras.applications.inception_v3.preprocess_input,  # Your preprocessing function\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "def custom_preprocessing(img):\n",
    "    \"\"\"\n",
    "    Applies InceptionV3 preprocessing, Color Jitter, and standardization.\n",
    "    \"\"\"\n",
    "    img = tf.keras.applications.inception_v3.preprocess_input(img)\n",
    "    img = color_jitter(img)\n",
    "    img = (img - img.mean()) / img.std()  # Standardization\n",
    "    return img\n",
    "\n",
    "# Create batches with augmentation for training data\n",
    "train_batches = datagen.flow_from_directory(\n",
    "    directory=train_path, \n",
    "    target_size=(299,299), \n",
    "    classes=['edible', 'poisonous'], \n",
    "    batch_size=32)\n",
    "\n",
    "\n",
    "# For validation and test data, only apply preprocessing (no augmentation)\n",
    "valid_batches = ImageDataGenerator(preprocessing_function=tf.keras.applications.inception_v3.preprocess_input) \\\n",
    "    .flow_from_directory(directory=valid_path, \n",
    "                         target_size=(299,299), \n",
    "                         classes=['edible', 'poisonous'], \n",
    "                         batch_size=32)\n",
    "\n",
    "\n",
    "test_batches = ImageDataGenerator(preprocessing_function=tf.keras.applications.inception_v3.preprocess_input) \\\n",
    "    .flow_from_directory(directory=test_path, \n",
    "                         target_size=(299,299), \n",
    "                         classes=['edible', 'poisonous'], \n",
    "                         batch_size=32, \n",
    "                         shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise the data\n",
    "imgs, labels = next(train_batches)\n",
    "\n",
    "# Plotting function to plot the processed images\n",
    "def plotImages(images_arr):\n",
    "    fig, axes = plt.subplots(1, 10, figsize=(20,20))\n",
    "    axes = axes.flatten()\n",
    "    for img, ax in zip( images_arr, axes):\n",
    "        ax.imshow(img)\n",
    "        ax.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotImages(imgs)\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the model\n",
    "base_model = tf.keras.applications.InceptionV3(include_top=False,  # exclude the top since we are training the model for a new task\n",
    "    weights=\"imagenet\",\n",
    "    input_tensor=None,\n",
    "    input_shape=(299,299,3),                       # there is only edible or poisonous\n",
    "    classifier_activation=\"softmax\",\n",
    "    name=\"incV3_base\",\n",
    ")\n",
    "\n",
    "# freeze the model\n",
    "base_model.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the inputs into the model\n",
    "inputs = tf.keras.layers.Input(shape=(299,299,3), name = \"input_layer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pass the inputs \n",
    "x = base_model(inputs)\n",
    "print(f\"The model shape after passing the inputs: {x.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Average pool layer the outputs of the base model\n",
    "x = tf.keras.layers.GlobalAveragePooling2D(name = \"Global-average-pooling-layer\")(x)\n",
    "print(f\"The shape after GlobalAveragePoolid2D: {x.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a Dense layer with trainable parameters\n",
    "x = Dense(units=32, activation='relu')(x) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add Dropout layer\n",
    "x = Dropout(rate=0.5)(x)  # Adjust dropout rate as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a Dense layer with trainable parameters\n",
    "x = Dense(units=16, activation='relu')(x) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add Dropout layer\n",
    "x = Dropout(rate=0.4)(x)  # Adjust dropout rate as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create the last output layer\n",
    "outputs = tf.keras.layers.Dense(no_of_classes, activation='softmax', name='output-layer')(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Merge the inputs and outputs into one model\n",
    "model = tf.keras.Model(inputs, outputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets play with training the model\n",
    "# Set all layers to non-trainable initially\n",
    "for layer in model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Make the last 2 layers trainable\n",
    "for layer in model.layers[-3:]:\n",
    "    layer.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.compile(loss = \"categorical_crossentropy\",\n",
    "              optimizer= tf.keras.optimizers.Adam(learning_rate=0.01),\n",
    "              metrics = [\"accuracy\"])\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_file = \"best_model.keras\"\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
    "\n",
    "callbacks = [\n",
    "    ModelCheckpoint(best_model_file, verbose=1, save_best_only=True, monitor=\"val_accuracy\"),\n",
    "    ReduceLROnPlateau(monitor=\"val_accuracy\", patience=4, factor=0.1, verbose=1, min_lr=1e-6),\n",
    "    EarlyStopping(monitor=\"val_accuracy\", patience=5, verbose=1)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "\n",
    "history = model.fit(train_batches,\n",
    "                    epochs=EPOCHS,\n",
    "                    steps_per_epoch= len(train_batches),\n",
    "                    validation_data=valid_batches,\n",
    "                    validation_steps=len(valid_batches),\n",
    "                    callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the test data\n",
    "\n",
    "print(model.evaluate(test_batches))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(history.history[\"loss\"]))\n",
    "print(len(history.history[\"val_loss\"]))\n",
    "print(len(history.history[\"accuracy\"]))\n",
    "print(len(history.history[\"val_accuracy\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# plot the results\n",
    "\n",
    "def plot_loss_curves(history):\n",
    "    loss = history.history[\"loss\"]\n",
    "    val_loss = history.history[\"val_loss\"]\n",
    "    accuracy = history.history[\"accuracy\"]\n",
    "    val_accuracy = history.history[\"val_accuracy\"]\n",
    "\n",
    "    epochs = range(len(loss))\n",
    "\n",
    "    # plot the loss\n",
    "    plt.plot(epochs, loss, label = \"training loss\")\n",
    "    plt.plot(epochs, val_loss, label=\"val_loss\")\n",
    "    plt.title(\"Loss\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "      # plot the accuracy\n",
    "    plt.plot(epochs, accuracy, label = \"training accuracy\")\n",
    "    plt.plot(epochs, val_accuracy, label=\"validation accuracy\")\n",
    "    plt.title(\"Accuracy\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# run the function\n",
    "plot_loss_curves(history)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
