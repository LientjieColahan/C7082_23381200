{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z43a3SM4Bfz2"
      },
      "source": [
        "# Mushroom edibility classification\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FKJP2UfRVYS-"
      },
      "source": [
        "**Student number: 23381200**\n",
        "**Date: 2025-01-16**\n",
        "\n",
        "Artificial Intelligence tools used in this assignment:\n",
        "- Google Gemini as a coding assistant\n",
        "- Perplexity AI Model as a research tool"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_kzc2D48Bfz3"
      },
      "source": [
        "# A. Background\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FXo4e08JU5kH"
      },
      "source": [
        "Mushrooms are a global dietary staple, valued for their low calorie and high nutrient content. A 2023 systematic review by De Cianni *et al.* highlights their umami flavour and potential as a plant-based protein alternative due to their texture and high-quality protein. However, the review notes the prevalence of mycophobia in some regions, driven somewhat by fears of poisoning.\n",
        "\n",
        "These fungi go beyond their culinary role as they emerge as powerful nutraceuticals, offering therapeutic potential in modern healthcare. A comprehensive analysis of fungal nutraceutical constituents conducted by Ma *et al.* (2018) demonstrated that mushrooms possess a diverse array of bioactive molecules including polysaccharides, proteins, glycoproteins, unsaturated fatty acids, phenolic compounds, tocopherols, ergosterols and lectins. This biochemical profile, coupled with their favorable nutritional composition positions mushrooms as potential therapeutic agents in preventive medicine.\n",
        "\n",
        "In Europe, for example, only 60 of the 269 edible mushroom taxa suitable for marketing are commercially cultivated, with the majority being wild varieties which if misidentified can have serious consequences. Thus mechanisms that enable the safe commercialisation of wild mushrooms are needed.\n",
        "\n",
        "Machine learning can be leveraged as a tool for the safe commercialisation of wild mushrooms in an industry set to grow from 18.39 million USD (US Dollar) in 2024 to 32.04 million USD by 2032 (Fortune Business Insights, 2024) by enabling accurate and robust classification of edible versus poisonous (or potentially poisonous) mushrooms.\n",
        "\n",
        "The objective of this project is to showcase 2 machine learning methods that have the potential to lead to the accurate classification of mushrooms. First an ensemble learning method showing the potential for classification based on tabular data. Second a deep learning method showcasing classification based on labelled images."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g3qcWNtiUiFW"
      },
      "source": [
        "# B. Methods"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qFfSf537UolY"
      },
      "source": [
        "## 1. Data description"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6tEYxKTjBfz3"
      },
      "source": [
        "\n",
        "The UC Irvine Machine Learning Repository provided the tabular dataset for this project (Wagner *et al.*, 2021a). This hypothetical mushroom dataset based on the 3rd edition of the book guide *Mushrooms and Toadstools* comprises 61069 theoretical capped mushrooms, representing 173 species with 353 mushrooms per species.\n",
        "\n",
        "Kaggle provided the database of imagery for this project (Kuno-Williams, 2022), these can be accessed via https://www.kaggle.com/datasets/derekkunowilliams/mushrooms/data. It contains 8781 jpg files of mushrooms representing 261 species gathered from Google. The mushrooms are classified as 'conditionally_edible', 'deadly', 'edible' and 'poisonous'. For the purpose of this assignment only the 'edible' and 'poisonous' images are considered.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xqyyFnq3UsKn"
      },
      "source": [
        "## 2. Model selection\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cGe7JH9nUxZl"
      },
      "source": [
        "Firstly the possibility of classifying mushroom edibility based on tabular data is explored by training a random forest model.This type of algorithm provides a more stable and accurate prediction compared to linear discriminant analysis, naive bayes and logistic regression (Wagner et al. 2021b) and is very flexible as it does not have any formal assumptions about the distribution. The RF builds a multiple decision trees which are combined to provide the prediction (Wagner *et al.*, 2021b).\n",
        "\n",
        "\n",
        "Second the potential for mushroom classification based on images using a convolutional neural network (CNN) was explored as these are commonly used for solving classification problems (Rawat et al., 2017). A basic CNN was built and different hyperparameter tuning was applied to get to the best model and evaluate its potential for mushroom classification. Then transfer learning was performed using the MobileNet2 model as the base with the imagenet weights applied to the model to leverage the model's existing capacity for image classification."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# For simplicity, we will use the gitpython library to clone the repository to the local machine.\n",
        "# Clone the GitHub repository on the local machine\n",
        "!pip install gitpython\n",
        "import git\n",
        "from git import Repo\n",
        "\n",
        "Repo.clone_from(\"https://github.com/LientjieColahan/C7082_23381200.git\", to_path=\"C:/Users/colah/OneDrive/Desktop/Clone\")\n",
        " \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PWXG_WnUBfz4"
      },
      "source": [
        "## 3. Random Forest Classifier training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F5nADulxBfz4"
      },
      "source": [
        "### Methods"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dJAVUx6o2BLZ"
      },
      "source": [
        "#### Data import and wrangling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wt6eF4fy2BLZ"
      },
      "source": [
        "The following code chunk downloads the necessary resources for data processing, model training, evaluation and visualisation in this assignment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3o5yvJT52BLZ"
      },
      "outputs": [],
      "source": [
        "# Import the necessary libraries\n",
        "\n",
        "import os \n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve\n",
        "from joblib import dump, load\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.layers import Dropout, Dense\n",
        "!pip install torchvision\n",
        "from torchvision import transforms\n",
        "import keras\n",
        "from keras import layers\n",
        "from tensorflow import data as tf_data\n",
        "import shutil\n",
        "import random\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M9_R15Wt2BLZ"
      },
      "source": [
        "The training dataset can be found in the GitHub repository under Model_training as '*secondary_mushroom_data.csv*' and the following code chunk imports the data directly from the raw data link from GitHub and separates the target variables, edible (e) or poisonous (p) from the features as well as doing manual data type conversions to ensure the data is in the correct format."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "aIaSTKNL2BLZ"
      },
      "outputs": [],
      "source": [
        "# URL of the raw CSV file in the GitHub repository\n",
        "url = \"https://raw.githubusercontent.com/LientjieColahan/C7082_23381200/refs/heads/main/Model_training/secondary_mushroom_data.csv\"\n",
        "\n",
        "# Load the database\n",
        "data = pd.read_csv(url, delimiter=';')\n",
        "# Separate features and target\n",
        "X = data.drop('class', axis=1)  # Features\n",
        "y = data['class']  # Target variable\n",
        "\n",
        "# Convert categorical variables to categorical data type\n",
        "categorical_columns = X.select_dtypes(include=['object']).columns\n",
        "X[categorical_columns] = X[categorical_columns].astype('category')\n",
        "\n",
        "# Convert target variable to categorical\n",
        "y = y.astype('category')\n",
        "\n",
        "# Convert continuous variables to float\n",
        "continuous_columns = ['cap-diameter', 'stem-height', 'stem-width']\n",
        "X[continuous_columns] = X[continuous_columns].astype(float)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DzUO0qCA2BLZ"
      },
      "source": [
        "#### Exploratory data analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "woNi4OUK2BLZ"
      },
      "source": [
        "Before training a model it is good practice to do some basic data analysis to make sure the data is suitable for model training. The code below gives an overview of the dataset and shows how many missing values there are for each feature."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9KV8Ja752BLZ",
        "outputId": "12280248-f125-49c1-d563-4bd579ef09a9"
      },
      "outputs": [],
      "source": [
        "# Display basic information about the dataset\n",
        "print(\"\\nFirst few rows of the features:\")\n",
        "print(X.head())\n",
        "print(\"\\nFirst few rows of the target:\")\n",
        "print(y.head())\n",
        "\n",
        "# Check for missing values\n",
        "print(\"\\nMissing values in the dataset:\")\n",
        "missing_values = X.isnull().sum()\n",
        "missing_percentages = (100 * X.isnull().sum() / len(X)).round(2)\n",
        "missing_table = pd.concat([missing_values, missing_percentages], axis=1, keys=['Count', 'Percentage'])\n",
        "missing_table = missing_table[missing_table['Count'] > 0].sort_values('Percentage', ascending=False)\n",
        "print(missing_table)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8QvdCuEW2BLZ"
      },
      "source": [
        "Determining if there are any features that relate to only one of the target variables is important as these types of features may cause bias in the training data making the model less generalisable. The following code chunk visualises the relationship between the categorical features and the target variables in bar plots."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 965
        },
        "id": "bvhuG6sB2BLa",
        "outputId": "7e219db6-6b22-498b-9dd9-7ffb8cdcec21"
      },
      "outputs": [],
      "source": [
        "# Explore relationship between categorical features and target variable through bar plot visualisations\n",
        "# Define the number of rows and columns for the grid\n",
        "num_rows = 4\n",
        "num_cols = 5\n",
        "\n",
        "# Create a figure and an array of subplots\n",
        "fig, axes = plt.subplots(num_rows, num_cols, figsize=(20, 16))\n",
        "\n",
        "# Flatten the axes array for easier iteration\n",
        "axes = axes.flatten()\n",
        "\n",
        "# Iterate through categorical columns and plot on subplots\n",
        "categorical_columns = data.select_dtypes(include=['object']).columns\n",
        "for i, column in enumerate(categorical_columns):\n",
        "    sns.countplot(x=column, hue='class', data=data, ax=axes[i])\n",
        "    axes[i].set_title(f'{column} vs. Target Variable', fontsize=10)\n",
        "    axes[i].tick_params(axis='x', rotation=45, labelsize=8)\n",
        "    axes[i].legend(title='Target Variable', fontsize=8)\n",
        "\n",
        "# Adjust layout to prevent overlapping\n",
        "plt.tight_layout()\n",
        "\n",
        "# Hide any unused subplots\n",
        "for i in range(len(categorical_columns), num_rows * num_cols):\n",
        "    fig.delaxes(axes[i])\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jFLzj0bX2BLa"
      },
      "source": [
        "Considering the missing values and the relationships between the features and the target it is reasonable to remove:\n",
        "\n",
        "*   Veil-type as it ha >90% missing values and there is only a single veil type in the dataset\n",
        "*   Veil-color as it has >85% missing values and only 1 veil colour encodes information for both the values in the target.\n",
        "* Spore-print-colour as it has >85% missing values and only 3 out of 7 spore print colours encode data for both the values in the target.\n",
        "* Stem-root as it has >80% missing values and only 2 out of 5 stem root types encode data for both values in the target\n",
        "\n",
        "The code chunk below removes these features."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "fArYrqg42BLa"
      },
      "outputs": [],
      "source": [
        "# Drop categorical variables which may bias the prediction\n",
        "X.drop(columns=['veil-type', 'veil-color', 'spore-print-color', 'stem-root'], inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l0t7TVCq2BLa"
      },
      "source": [
        "The distribution of the data between edible and poisonous needs to be close to 50/50 in order to prevent bias during training. The following code checks the spread of the data after feature removal."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 673
        },
        "id": "WzkBIBzS2BLa",
        "outputId": "b10d8083-feac-4701-b1a3-178747fca217"
      },
      "outputs": [],
      "source": [
        "# Check the data spread between edible and poisonous\n",
        "plt.figure(figsize=(10, 6))\n",
        "ax = sns.countplot(x='class', data=data)  # Use 'class' column for x-axis\n",
        "plt.title('Distribution of Edible vs. Poisonous')\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "\n",
        "# Calculate percentage for each bar\n",
        "total = len(data['class'])\n",
        "for p in ax.patches:\n",
        "    percentage = '{:.1f}%'.format(100 * p.get_height() / total)\n",
        "    x_coord = p.get_x() + p.get_width() / 2 - 0.1\n",
        "    y_coord = p.get_y() + p.get_height()\n",
        "    ax.annotate(percentage, (x_coord, y_coord), size=12)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QBkmYsGR2BLa"
      },
      "source": [
        "### Model creation and training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aFuk815o2BLa"
      },
      "source": [
        "Machine learning models have certain universal requirements for model training - the data has to be numerical and there needs to be a subset of data for training, validation (in deep learning) and testing. The following code chunk processes the data to make it suitable for the task of training a random forest classifier by using one-hot encoding to assign binary values to the categorical features and creating a 80:20 split in the data for training and testing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "eEYGmYfY2BLa"
      },
      "outputs": [],
      "source": [
        "# Encode categorical variables\n",
        "encoder = LabelEncoder()\n",
        "y_encoded = encoder.fit_transform(y)  # Encode target variable (edible=0, poisonous=1)\n",
        "X_encoded = pd.get_dummies(X)  # One-hot encode categorical features\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_encoded, y_encoded,\n",
        "                                                    test_size=0.2,\n",
        "                                                    random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RstDobvk2BLa"
      },
      "source": [
        "As a starting point a preliminary random forest model is trained using the training data as is. Then that model can be used to extract the feature importances and a grid search can be done as hyper parameter tuning to find the best model. The following code chunk trains a preliminary model, applies feature selection and then implements a grid search to find the optimal combination of model parameters. The preliminary model is then retrained with the optimised features to give the most accurate prediction model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 599
        },
        "id": "FuaO1yU62BLa",
        "outputId": "f79e265a-7142-41cf-cd18-15ff57c065b8"
      },
      "outputs": [],
      "source": [
        "# Train a preliminary RF model to enable feature selection\n",
        "rf_prelim = RandomForestClassifier(random_state=42)\n",
        "rf_prelim.fit(X_train, y_train)\n",
        "\n",
        "# Perform feature selection using feature importance\n",
        "feature_importances = pd.DataFrame({'Feature': X_encoded.columns,\n",
        "                                    'Importance': rf_prelim.feature_importances_})\n",
        "feature_importances.sort_values(by='Importance', ascending=False, inplace=True)\n",
        "\n",
        "# Hyperparameter tuning using GridSearchCV\n",
        "param_grid = {'n_estimators': [2 ,30, 100],  # the number of trees in the forest\n",
        "              'max_depth': [1, 10],  # the maximum depth of trees\n",
        "              'min_samples_split': [2, 3, 5],  # the minimum samples required to split an internal node\n",
        "              'min_samples_leaf': [1, 2]}   # the minimum samples required to be at a leaf node\n",
        "\n",
        "# Create a pipeline\n",
        "grid_search = GridSearchCV(estimator=rf_prelim,\n",
        "                           param_grid=param_grid,\n",
        "                           cv=16,   # 16-fold cross-validation\n",
        "                           scoring='accuracy',  # accuracy as the scoring metric\n",
        "                           verbose=1)\n",
        "\n",
        "# Fit the grid search model\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Plot feature importance\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(x='Importance', y='Feature', data=feature_importances.head(10))\n",
        "plt.title('Top 10 Important Features')\n",
        "plt.show()\n",
        "\n",
        "# Best parameters and model from GridSearchCV\n",
        "best_rf_model = grid_search.best_estimator_\n",
        "print(\"Best Parameters:\", grid_search.best_params_)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j3BoJ1ZR2BLa"
      },
      "source": [
        "The following code chunk saves the best model to the cloned GitHub repository. This file is available in the GitHub repository under Assignment as *best_rf_model.joblib*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o32w5GfG6ZQ6"
      },
      "source": [
        "|Best Parameters     |        |\n",
        "|--------------- ----|--------|\n",
        "|Max Depth           | 10     |\n",
        "|Max Samples per Leaf| 1      |\n",
        "|Min samples per split| 2    |\n",
        "|Number of estimators| 100  |\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KqgL7Nkz2BLb"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Save the best model using joblib\n",
        "dump(best_rf_model, 'C:/Users/colah/OneDrive/Documents/GitHub/C7082_23381200/Assignment/best_rf_model.joblib')\n",
        "# replace the file path with the path to the directory where you want to save the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fcq9OY2uBfz4"
      },
      "source": [
        "### Results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The classification report indicates that the random forest model performed very well on this theoretical mushroom dataset with an accuracy of 98%. The precision and recall is high for both classes showing that the model is able to identify both poisonous and edible mushrooms with minimal false positives or false negatives. The high F-1 scores across both classes indicate a good balance between precision and recall. Even though the dataset is slightly unbalanced the macro and weighted averages show there is consistent performance across classes. \n",
        "\n",
        "The ROC curve provides further illustration of how accurate the model's prediction is when considering the steep almost vertical blue line showing the increase in accuracy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1AOkB7Iv2BLb"
      },
      "source": [
        "Classification Report:\n",
        "\n",
        "|              ||Precision||    Recall||  f1-score||   Support||\n",
        "|--------------||---------||----------||----------||----------||\n",
        "|           0  ||   0.97  ||    0.98  ||  0.97    ||   5374   ||\n",
        "|           1  ||   0.98  ||    0.98  ||  0.98    ||   6840   ||\n",
        "|              ||         ||          ||          ||          ||\n",
        "|    accuracy  ||         ||          ||  0.98    ||   12214  ||\n",
        "|   macro avg  ||   0.98  ||   0.98   ||  0.98    ||   12214  ||\n",
        "|weighted avg  ||   0.98  ||   0.98   ||  0.98    ||   12214  ||"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "IsOwz3Kf2BLb"
      },
      "outputs": [],
      "source": [
        "# Evaluate model performance on test set\n",
        "y_pred = best_rf_model.predict(X_test)\n",
        "y_pred_proba = best_rf_model.predict_proba(X_test)[:, 1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bl8pgzh92BLb"
      },
      "outputs": [],
      "source": [
        "# Classification report and confusion matrix\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Greens', xticklabels=['Edible', 'Poisonous'], yticklabels=['Edible', 'Poisonous'])\n",
        "plt.title('Confusion Matrix')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "#plt.show()\n",
        "plt.savefig('C:/Users/colah/OneDrive/Documents/GitHub/C7082_23381200/Assignment/Outputs/Confusion_Matrix.png')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "csztMHpX2BLb",
        "outputId": "2d1a4d7b-e43e-42f9-960a-9b0ad7f0ad9d"
      },
      "outputs": [],
      "source": [
        "# ROC Curve and AUC Score\n",
        "fpr, tpr, _ = roc_curve(y_test, y_pred_proba)\n",
        "roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(fpr, tpr, label=f'ROC Curve (AUC = {roc_auc:.2f})')\n",
        "plt.plot([0, 1], [0, 1], 'k--')  # Diagonal line for random guess\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XbFv-PUeBfz6"
      },
      "source": [
        "## 4. Convolutional Neural Network training\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aDHqITL_Tb-Q"
      },
      "source": [
        "### Methods"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Data Preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The mushroom image dataset was downloaded from kaggle and two folders 'deadly' and 'conditionally_edible' were deleted manually as they are superfluous to the current assignment. The edible ad poisonous mushroom images split into training, testing and validation directories using the code in *CNN_dataset_framework.ipynb* located in the Model_training directory.\n",
        "\n",
        "In summary the data was divided 80:20 into training and testing data, and then the training data was subdivided following the 80:20 rule again yielding a balanced dataset of 1584 training images, 396 validation images and 495 testing images for both edible and poisonous mushrooms."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The mushroom_dataset directory in the C7082 Git contains the image directory structure ready to be used in model training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Change the working directory to the cloned repository\n",
        "os.chdir('C:/Users/colah/OneDrive/Desktop/Clone') # Change the path to the location of the cloned repository\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Build a basic model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Before building the model the images that will be used need to be transformed from their raw state into a format that can be utilised by the model. The pre-processing of images includes standardisation, noise reduction, feature enhancement, dimensionality reduction and data augmentation. Processing does not only make them suitable for use in the model, but it can improve model performance by reducing the computational load during training.\n",
        "\n",
        "\n",
        "The following code uses TensorFlow's image preprocessing functions to load, resize, create batches and standardise the mushroom images, preparing them for training a machine learning model. Followed by data augmentation to expand the dataset since the original dataset is quite small."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Image preprocessing for basic CNN\n",
        "# Define common parameters\n",
        "image_size = (224, 224)\n",
        "batch_size = 32\n",
        "\n",
        "# Create train dataset\n",
        "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    'C:/Users/colah/OneDrive/Desktop/Clone/Model_training/mushroom_dataset/train', # replace with the path to the train folder\n",
        "    image_size=image_size,\n",
        "    batch_size=batch_size,\n",
        "    label_mode='binary',\n",
        "    class_names=['edible', 'poisonous'],\n",
        "    shuffle=True)\n",
        "\n",
        "# Normalize pixel values\n",
        "train_ds=train_ds.map(lambda x, y: (x/255, y))\n",
        "\n",
        "# Create validation dataset\n",
        "valid_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    'C:/Users/colah/OneDrive/Desktop/Clone/Model_training/mushroom_dataset/valid', # replace with the path to the valid folder\n",
        "    image_size=image_size,\n",
        "    batch_size=batch_size,\n",
        "    label_mode='binary',\n",
        "    class_names=['edible', 'poisonous'],\n",
        "    shuffle=False)\n",
        "\n",
        "# Normalize pixel values\n",
        "valid_ds=valid_ds.map(lambda x, y: (x/255, y))\n",
        "\n",
        "# Create test dataset\n",
        "test_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    'C:/Users/colah/OneDrive/Desktop/Clone/Model_training/mushroom_dataset/test', # replace with the path to the test folder\n",
        "    image_size= image_size,\n",
        "    batch_size=batch_size,\n",
        "    label_mode='binary',\n",
        "    class_names=['edible', 'poisonous'],\n",
        "    shuffle=False)\n",
        "\n",
        "# Data Augmentation with Keras ImageDataGenerator\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest')\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    'C:/Users/colah/OneDrive/Desktop/Clone/Model_training/mushroom_dataset/train', # replace with the path to the train folder\n",
        "    target_size=image_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The following code chunk implements a Convolutional Neural Network (CNN) with several modern architectural features aimed at binary image classification. \n",
        "\n",
        "\n",
        "There are 3 main sections to the model. The first section has a Conv2D layer which learns basic features in the images, and a BatchNormalisation layer with a ReLU activation to help speed up training. The second section of the model has 2 identical blocks with different filters (128 and 64) aimed at extracting the main features. These blocks use a more efficient SeperableConv2D layer and implement residual connections to help alleviate vanishing gradients. There are also MaxPooling layers which reduce dimensionality whilst retaining the important features. The third section of the model has a SeparableConv2D layer to capture high level features, a GlobalAveragePooling2D layer to reduce the spacial dimensions to a single vector, a dropout layer where 25% of neurons are randomly deactivated during training to prevent overfitting and a final Dense layer with a sigmoid activation function which outputs a probability for either edible or poisonous. The sigmoid activation function is used along with the binary cross entropy loss function when the model is compiled which can improve model accuracy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [],
      "source": [
        "def make_model(input_shape, num_classes):\n",
        "    inputs = keras.Input(shape=input_shape)\n",
        "\n",
        "    # Entry block\n",
        "    x = layers.Conv2D(64, 3, strides=2, padding=\"same\")(inputs)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Activation(\"relu\")(x)\n",
        "\n",
        "    previous_block_activation = x  # Set aside residual\n",
        "\n",
        "    for size in [128, 64]:\n",
        "        x = layers.Activation(\"relu\")(x)\n",
        "        x = layers.SeparableConv2D(size, 3, padding=\"same\")(x)\n",
        "        x = layers.BatchNormalization()(x)\n",
        "\n",
        "        x = layers.Activation(\"relu\")(x)\n",
        "        x = layers.SeparableConv2D(size, 3, padding=\"same\")(x)\n",
        "        x = layers.BatchNormalization()(x)\n",
        "\n",
        "        x = layers.MaxPooling2D(3, strides=2, padding=\"same\")(x)\n",
        "\n",
        "        # Project residual\n",
        "        residual = layers.Conv2D(size, 1, strides=2, padding=\"same\")(\n",
        "            previous_block_activation\n",
        "        )\n",
        "        x = layers.add([x, residual])  # Add back residual\n",
        "        previous_block_activation = x  # Set aside next residual\n",
        "\n",
        "    x = layers.SeparableConv2D(512, 3, padding=\"same\")(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Activation(\"relu\")(x)\n",
        "\n",
        "    x = layers.GlobalAveragePooling2D()(x)\n",
        "    if num_classes == 2:\n",
        "        units = 1\n",
        "    else:\n",
        "        units = num_classes\n",
        "\n",
        "    x = layers.Dropout(0.25)(x)\n",
        "    \n",
        "    # We specify activation=None so as to return logits\n",
        "    outputs = layers.Dense(1, activation='sigmoid')(x)\n",
        "    return keras.Model(inputs, outputs)\n",
        "\n",
        "\n",
        "model_basic = make_model(input_shape=image_size + (3,), num_classes=2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Train the model\n",
        "epochs = 100\n",
        "\n",
        "callbacks = [keras.callbacks.ModelCheckpoint(\"Best_basic_model.keras\", save_best_only=True),\n",
        "    ReduceLROnPlateau(monitor=\"val_accuracy\", patience=4, factor=0.1, verbose=1, min_lr=1e-6),\n",
        "    EarlyStopping(monitor=\"val_accuracy\", patience=50, verbose=1, mode = 'max')]\n",
        "\n",
        "model_basic.compile(optimizer=keras.optimizers.Adam(0.1),\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_basic = model_basic.fit(train_ds,\n",
        "                     epochs=epochs,\n",
        "                     callbacks=callbacks,\n",
        "                     validation_data=valid_ds)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eIVpRcPPTfS0"
      },
      "source": [
        "#### Results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The following code chunk draws the basic CNN model's accuracy and loss curves tho give a visual representation of the training process"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sPXqjuiHTjxu"
      },
      "outputs": [],
      "source": [
        "# Plot training & validation accuracy values\n",
        "plt.plot(model_basic.history['accuracy']) \n",
        "plt.plot(model_basic.history['val_accuracy'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "# Plot training & validation loss values\n",
        "plt.plot(model_basic.history['loss'])\n",
        "plt.plot(model_basic.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The basic CNN model does not perform well at the task of classifying mushrooms as edible or poisonous with the best training accuracy being 0.58 (58%) and validation accuracy being 0.5745 (57.45%) at epoch 31. These are only marginally better than a guess.\n",
        "\n",
        "These results have led on to using transfer learning in an attempt to improve the prediction accuracy of a CNN for mushroom classification."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Transfer learning with MobileNet2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Transfer learning is a commonly used machine learning technique where a model developed for one task is used as the starting point for a different, but related task. By using the pretrained model as a base whe training a model for a related task you can utilise the learned features and patterns that have been acquired while solving the original problem and apply them to a new context, significantly reducing the amount of training data and computational resources required. The pre-trained model's learned representations often capture universal features that are valuable across similar domains.\n",
        "\n",
        "\n",
        "MobileNetV2 is a lightweight convolutional neural network architecture specifically designed for mobile and edge devices. The model achieves high accuracy while maintaining computational efficiency through the use of depthwise separable convolutions and linear bottlenecks. These characteristics make MobileNetV2 particularly suitable for transfer learning in image classification tasks because its architecture efficiently captures hierarchical visual features - from simple edges and textures in early layers to more complex object parts in deeper layers - while maintaining a relatively small parameter count. This means it is possible to fine-tune the model on new datasets without excessive computational costs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The following code chunk preprosses the data ready for training on the MobileNetV2 model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define common parameters\n",
        "image_size = (224, 224)\n",
        "batch_size = 12\n",
        "\n",
        "# Preprocessing for MobileNetV2\n",
        "def preprocess(image, label):\n",
        "    image = tf.image.convert_image_dtype(image, dtype=tf.float32)  # Convert to float32\n",
        "    image = tf.keras.applications.mobilenet_v2.preprocess_input(image)  # Apply MobileNetV2 preprocessing\n",
        "    return image, label\n",
        "\n",
        "# Create train dataset\n",
        "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    'C:/Users/colah/OneDrive/Desktop/Clone/Model_training/mushroom_dataset/train', # replace with the path to the train folder\n",
        "    image_size=image_size,\n",
        "    batch_size=batch_size,\n",
        "    label_mode='binary',\n",
        "    class_names=['edible', 'poisonous'],\n",
        "    shuffle=True)\n",
        "\n",
        "# Create validation dataset\n",
        "valid_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    'C:/Users/colah/OneDrive/Desktop/Clone/Model_training/mushroom_dataset/valid', # replace with the path to the valid folder\n",
        "    image_size=image_size,\n",
        "    batch_size=batch_size,\n",
        "    label_mode='binary',\n",
        "    class_names=['edible', 'poisonous'],\n",
        "    shuffle=False)\n",
        "\n",
        "# Create test dataset\n",
        "test_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    'C:/Users/colah/OneDrive/Desktop/Clone/Model_training/mushroom_dataset/test', # replace with the path to the test folder\n",
        "    image_size=image_size,\n",
        "    batch_size=batch_size,\n",
        "    label_mode='binary',\n",
        "    class_names=['edible', 'poisonous'],\n",
        "    shuffle=False)\n",
        "\n",
        "# Apply MobileNetV2 preprocessing to datasets\n",
        "train_ds = train_ds.map(preprocess)\n",
        "valid_ds = valid_ds.map(preprocess)\n",
        "test_ds = test_ds.map(preprocess)\n",
        "\n",
        "# Data Augmentation with Keras ImageDataGenerator for the training and validation datasets\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest')\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    'C:/Users/colah/OneDrive/Desktop/Clone/Model_training/mushroom_dataset/train', # replace with the path to the train folder\n",
        "    target_size=image_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary')\n",
        "\n",
        "valid_datagen = ImageDataGenerator(\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest')\n",
        "\n",
        "valid_generator = valid_datagen.flow_from_directory(\n",
        "    'C:/Users/colah/OneDrive/Desktop/Clone/Model_training/mushroom_dataset/valid', # replace with the path to the valid folder\n",
        "    target_size=image_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The code chunk below creates the base model ready for transfer learning. MobileNetV2 requires an input shape of (224,224,4) which is why it is defined in the code."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# Define input shape and number of classes\n",
        "input_shape = (224, 224, 3)\n",
        "num_classes = 2 \n",
        "\n",
        "EPOCHS = 50 \n",
        "\n",
        "# Create the base model\n",
        "base_model = keras.applications.MobileNetV2(\n",
        "    input_shape=input_shape,\n",
        "    include_top=False,\n",
        "    weights=\"imagenet\"\n",
        ")\n",
        "\n",
        "# Freeze the base model\n",
        "base_model.trainable = False\n",
        "\n",
        "\n",
        "# Create the new model\n",
        "model = keras.Sequential([\n",
        "    base_model,\n",
        "    keras.layers.GlobalAveragePooling2D(),\n",
        "    keras.layers.Dense(256, activation='relu'),\n",
        "    keras.layers.Dropout(0.2),\n",
        "    keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(\n",
        "    optimizer=keras.optimizers.Adam(learning_rate=0.0001),\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "callbacks = [keras.callbacks.ModelCheckpoint(\"Best_trasf_model.keras\", save_best_only=True),\n",
        "    ReduceLROnPlateau(monitor=\"val_accuracy\", patience=4, factor=0.1, verbose=1, min_lr=1e-6),\n",
        "    EarlyStopping(monitor=\"val_accuracy\", patience=50, verbose=1, mode = 'max')]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "    train_ds,\n",
        "    steps_per_epoch=len(train_ds) // batch_size,\n",
        "    epochs=EPOCHS,\n",
        "    callbacks=callbacks,\n",
        "    validation_data=valid_ds,\n",
        "    validation_steps=len(valid_ds) // batch_size,) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nWC7ReR3Bfz6"
      },
      "source": [
        "### Results\n",
        "The following code chunk draws the basic CNN model's accuracy and loss curves that give a visual representation of the training process"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot training & validation accuracy values\n",
        "plt.plot(history.history['accuracy']) \n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "# Plot training & validation loss values\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The tansfer learning based model performs better on the classification task in half the number of epochs (50 vs 100) but with the best training accuracy of 0.7607 (76.07%) and validation accuracy of 0.8833 (88.33%) reached at epoch 50 this model shows promise but is not yet suitable for practical use.\n",
        "\n",
        "Using other pretrained models such as VGG16 or InceptionV3 as a base might improve the accuracy making the deployment of this type of tool more realistic.\n",
        "\n",
        "There is also a need for a database of more images as even with the image generator function in place the model still runs into an error where there is not enough input data and increasing the primary database of images will help alleviate this problem."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UfIKG-ljBfz6"
      },
      "source": [
        "# D. Discussion\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T8UyoevkVNuV"
      },
      "source": [
        "Different types of data about mushroom characteristics and their edibility exist in various formats across scientific literature, field guides, and digital repositories. While traditional taxonomic data is often structured in tabular format, capturing features like cap size, stem characteristics, and spore colour, there is also a wealth of visual information available as images. Modern machine learning approaches can leverage both these data sources through ensemble or deep learning techniques. By using both approaches the system can benefit from the strengths of each data format - the precision of measured attributes in tabular data and the rich contextual information present in images - potentially leading to more robust and accurate predictions of mushroom edibility than would be possible using either data type alone.\n",
        "\n",
        "In conclusion, this investigation of machine learning approaches for mushroom classification provides context for the development of mutliple machine learning appraoches as steps toward supporting the growing commercial mushroom industry, while highlighting important limitations. Although the random forest classifier demonstrated high accuracy using tabular data, and the convolutional neural network shows potential for image-based classification, neither approach is currently suitable for autonomous deployment. Instead, these methods could be developed in parallel and potentially combined to create a preliminary screening tool to support experts in mushroom identification. This kind of hybrid approach, when used alongside specialist verification, could help address the mycophobia noted by De Cianni et al. (2023) by providing an additional layer of safety verification in the identification process.\n",
        "\n",
        "The development of such complementary computational tools becomes increasingly relevant as the mushroom industry expands toward its projected $32.04 million valuation by 2032. Future work should focus on expanding both tabular and image datasets, refining the machine learning architectures, and crucially, investigating how these approaches could be integrated to leverage their respective strengths while maintaining rigorous safety standards. This could eventually enable rapid initial screening of mushrooms, making the rich nutritional and nutraceutical benefits documented by Ma et al. (2018) more accessible, while ensuring safety through mandatory expert verification. There is promise in developing AI-assisted tools that can support specialists in expanding safe access to wild mushrooms' nutritional and therapeutic potential."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JvAAjJ0bBfz6"
      },
      "source": [
        "# E. Literature\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BDMG0JfDVRHU"
      },
      "source": [
        "De Cianni, R., Pippinato, L. and Mancuso, T. (2023) 'A systematic review on drivers influencing consumption of edible mushrooms and innovative mushroom-containing products', Appetite, 182, pp. 106454. doi: 10.1016/j.appet.2023.106454.\n",
        "\n",
        "Kuno-Williams, D. (2022) Mushrooms. Available at: https://www.kaggle.com/datasets/derekkunowilliams/mushrooms/data?select=mushroom_dataset (Accessed: 2024-12-08).\n",
        "\n",
        "Fortune Business Insights (2024) Mushroom Market Size, Share & Industry Analysis, By Type (Button, Shiitake, Oyster, and Others), By Form (Fresh, Frozen, Dried, and Canned), and Regional Forecast, 2024-2032. Available at: https://www.fortunebusinessinsights.com/industry-reports/infographics/mushroom-market-100197 (Accessed: 2024/12/05).\n",
        "\n",
        "Ma, G., Yang, W., Zhao, L., Pei, F., Fang, D. and Hu, Q. (2018) 'A critical review on the health promoting effects of mushrooms nutraceuticals', Food Science and Human Wellness, 7(2), pp. 125133. doi: 10.1016/j.fshw.2018.05.002.\n",
        "\n",
        "Rawat, W. and Wang, Z. (2017) 'Deep Convolutional Neural Networks for Image Classification: A Comprehensive Review', Neural Computation, 29(9), pp. 23522449. doi: 10.1162/neco_a_00990.\n",
        "\n",
        "Wagner, D., Heider, D. and Hattab, G. (2021a) 'Secondary Mushroom', UCI Machine Learning Repository, 2021. [Online]. Available: https://doi.org/10.24432/C5FP5Q. (Accessed: 2024/12/05)\n",
        "\n",
        "Wagner, D., Heider, D. and Hattab, G. (2021b) 'Mushroom data creation, curation, and simulation to support classification tasks', Scientific Reports, 11(1), pp. 8134. doi: 10.1038/s41598-021-87602-3.\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
